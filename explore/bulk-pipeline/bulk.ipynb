{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute DWPCs for all metapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import pathlib\n",
    "import scipy.sparse\n",
    "import tqdm\n",
    "\n",
    "import hetmech.degree_weight\n",
    "from hetmech.hetmat import HetMat\n",
    "import hetmech.hetmat.caching\n",
    "import hetmech.matrix\n",
    "import hetmech.degree_group\n",
    "import hetmech.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hetmat = HetMat('../../data/hetionet-v1.0.hetmat/')\n",
    "hetmech.degree_weight.default_dwwc_method = hetmech.degree_weight.dwwc_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All metapaths up to length 2\n",
    "metapaths = hetmat.metagraph.extract_metapaths('Disease', max_length=2)\n",
    "metapaths = ['CbGaD', 'GpBPpGiG']\n",
    "len(metapaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute path counts\n",
    "\n",
    "Note that we probably want to make this more intelligent to not read then write inverse of an existing on-disk metapath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [05:14<00:00, 157.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 10s, sys: 3.32 s, total: 5min 13s\n",
      "Wall time: 5min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hetmat.path_counts_cache = hetmech.hetmat.caching.PathCountPriorityCache(hetmat, allocate_GB=16)\n",
    "for metapath in tqdm.tqdm(metapaths):\n",
    "    row_ids, col_ids, pc_matrix = hetmech.degree_weight.dwpc(hetmat, metapath, damping=0, dense_threshold=0.7, dtype='uint64')\n",
    "    path = hetmat.get_path_counts_path(metapath, 'dwpc', 0, None)\n",
    "    if not path.exists():\n",
    "        hetmech.hetmat.save_matrix(pc_matrix, path)\n",
    "    del pc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathCountPriorityCache containing 2 items\n",
      "  total gets: 2\n",
      "  cache hits: memory = 0, disk = 2, absent = 0\n",
      "  2.06 GB in use of 16.00 GB allocated\n"
     ]
    }
   ],
   "source": [
    "print(hetmat.path_counts_cache.get_stats())\n",
    "hetmat.path_counts_cache = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute DWPCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [05:22<00:00, 161.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 11s, sys: 8.44 s, total: 5min 19s\n",
      "Wall time: 5min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hetmat.path_counts_cache = hetmech.hetmat.caching.PathCountPriorityCache(hetmat, allocate_GB=16)\n",
    "mean_dwpcs = dict()\n",
    "for metapath in tqdm.tqdm(metapaths):\n",
    "    row_ids, col_ids, dwpc_matrix = hetmech.degree_weight.dwpc(hetmat, metapath, damping=0.5, dense_threshold=0.7, dtype='float64')\n",
    "    mean_dwpcs[(metapath, 'dwpc', 0.5)] = dwpc_matrix.mean()\n",
    "    path = hetmat.get_path_counts_path(metapath, 'dwpc', 0.5, None)\n",
    "    if not path.exists():\n",
    "        hetmech.hetmat.save_matrix(dwpc_matrix, path)\n",
    "    del dwpc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathCountPriorityCache containing 2 items\n",
      "  total gets: 2\n",
      "  cache hits: memory = 0, disk = 2, absent = 0\n",
      "  2.06 GB in use of 16.00 GB allocated\n"
     ]
    }
   ],
   "source": [
    "print(hetmat.path_counts_cache.get_stats())\n",
    "hetmat.path_counts_cache = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate running DGP metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:59:09<00:00, 35.75s/it]\n"
     ]
    }
   ],
   "source": [
    "for name, permat in tqdm.tqdm(hetmat.permutations.items()):\n",
    "    permat.path_counts_cache = hetmech.hetmat.caching.PathCountPriorityCache(permat, allocate_GB=16)\n",
    "    for metapath in metapaths:\n",
    "        degree_grouped_df = hetmech.degree_group.single_permutation_degree_group(\n",
    "            permat, metapath, dwpc_mean=mean_dwpcs[(metapath, 'dwpc', 0.5)], damping=0.5)\n",
    "        path = hetmat.get_running_degree_group_path(metapath, 'dwpc', 0.5, extension='.pkl')\n",
    "        if path.exists():\n",
    "            running_df = pandas.read_pickle(path)\n",
    "            running_df += degree_grouped_df\n",
    "        else:\n",
    "            running_df = degree_grouped_df\n",
    "        running_df.to_pickle(path)\n",
    "    permat.path_counts_cache = None\n",
    "\n",
    "# Replace .pkl files with .tsv.gz files.\n",
    "for metapath in metapaths:\n",
    "    old_path = hetmat.get_running_degree_group_path(metapath, 'dwpc', 0.5, extension='.pkl')\n",
    "    df = pandas.read_pickle(old_path)\n",
    "    new_path = hetmat.get_running_degree_group_path(metapath, 'dwpc', 0.5, extension='.tsv.gz')\n",
    "    df.to_csv(new_path, sep='\\t', compression='gzip')\n",
    "    old_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine DWPC with DGP & calculate p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, group_size):\n",
    "    \"\"\"\n",
    "    Group an iterable into chunks of group_size.\n",
    "    Derived from https://stackoverflow.com/a/8998040/4651668\n",
    "    \"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    while True:\n",
    "        chunk = itertools.islice(iterable, group_size)\n",
    "        try:\n",
    "            head = next(chunk),\n",
    "        except StopIteration:\n",
    "            break\n",
    "        yield itertools.chain(head, chunk)\n",
    "\n",
    "def grouped_tsv_writer(row_generator, path, group_size=20_000, sep='\\t', index=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Write an iterable of dictionaries to a TSV, where each dictionary is a row.\n",
    "    \"\"\"\n",
    "    chunks = grouper(row_generator, group_size=group_size)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        df = pandas.DataFrame.from_records(chunk)\n",
    "        kwargs['header'] = not bool(i)\n",
    "        kwargs['mode'] = 'a' if i else 'w'\n",
    "        df.to_csv(path, sep=sep, index=index, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.31it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for metapath in tqdm.tqdm(metapaths):\n",
    "    dwpcs_rows = hetmech.pipeline.combine_dwpc_dgp(hetmat, metapath, damping=0.5, ignore_zeros=True, max_p_value=0.05)\n",
    "    path = hetmat.directory.joinpath('adjusted-path-counts', 'dwpc-0.5',\n",
    "                                     'adjusted-dwpcs', f'{metapath}-filtered.tsv.gz')\n",
    "    grouped_tsv_writer(dwpcs_rows, path, float_format='%.7g', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hetmech]",
   "language": "python",
   "name": "conda-env-hetmech-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
