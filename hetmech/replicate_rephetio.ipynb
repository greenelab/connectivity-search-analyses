{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform all necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load matrix.py\n",
    "from collections import OrderedDict\n",
    "\n",
    "import hetio.hetnet\n",
    "import numpy\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def get_node_to_position(graph, metanode):\n",
    "    \"\"\"\n",
    "    Given a metanode, return a dictionary of node to position\n",
    "    \"\"\"\n",
    "    if not isinstance(metanode, hetio.hetnet.MetaNode):\n",
    "        # metanode is a name\n",
    "        metanode = graph.metagraph.node_dict[metanode]\n",
    "    metanode_to_nodes = graph.get_metanode_to_nodes()\n",
    "    nodes = sorted(metanode_to_nodes[metanode])\n",
    "    node_to_position = OrderedDict((n, i) for i, n in enumerate(nodes))\n",
    "    return node_to_position\n",
    "\n",
    "\n",
    "def metaedge_to_adjacency_matrix(graph, metaedge, dtype=numpy.bool_,\n",
    "                                 sparse_threshold=0):\n",
    "    \"\"\"\n",
    "    Returns an adjacency matrix where source nodes are rows and target\n",
    "    nodes are columns.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    graph : hetio.hetnet.graph\n",
    "    metaedge : hetio.hetnet.MetaEdge\n",
    "    dtype : type\n",
    "    sparse_threshold : float (0 < sparse_threshold < 1)\n",
    "        sets the density threshold above which a sparse matrix will be\n",
    "        converted to a dense automatically.\n",
    "    \"\"\"\n",
    "    if not isinstance(metaedge, hetio.hetnet.MetaEdge):\n",
    "        # metaedge is an abbreviation\n",
    "        metaedge = graph.metagraph.metapath_from_abbrev(metaedge)[0]\n",
    "    source_nodes = list(get_node_to_position(graph, metaedge.source))\n",
    "    target_node_to_position = get_node_to_position(graph, metaedge.target)\n",
    "    shape = len(source_nodes), len(target_node_to_position)\n",
    "    row, col, data = [], [], []\n",
    "    for i, source_node in enumerate(source_nodes):\n",
    "        for edge in source_node.edges[metaedge]:\n",
    "            row.append(i)\n",
    "            col.append(target_node_to_position[edge.target])\n",
    "            data.append(1)\n",
    "    adjacency_matrix = sparse.csc_matrix((data, (row, col)), shape=shape,\n",
    "                                         dtype=dtype)\n",
    "    adjacency_matrix = auto_convert(adjacency_matrix, sparse_threshold)\n",
    "    row_names = [node.identifier for node in source_nodes]\n",
    "    column_names = [node.identifier for node in target_node_to_position]\n",
    "    return row_names, column_names, adjacency_matrix\n",
    "\n",
    "\n",
    "def normalize(matrix, vector, axis, damping_exponent):\n",
    "    \"\"\"\n",
    "    Normalize a 2D numpy.ndarray in place.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    matrix : numpy.ndarray or scipy.sparse\n",
    "    vector : numpy.ndarray\n",
    "        Vector used for row or column normalization of matrix.\n",
    "    axis : str\n",
    "        'rows' or 'columns' for which axis to normalize\n",
    "    damping_exponent : float\n",
    "        exponent to use in scaling a node's row or column\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2\n",
    "    assert vector.ndim == 1\n",
    "    if damping_exponent == 0:\n",
    "        return matrix\n",
    "    with numpy.errstate(divide='ignore'):\n",
    "        vector **= -damping_exponent\n",
    "    vector[numpy.isinf(vector)] = 0\n",
    "    shape = (len(vector), 1) if axis == 'rows' else (1, len(vector))\n",
    "    vector = vector.reshape(shape)\n",
    "    if sparse.issparse(matrix):\n",
    "        matrix = matrix.multiply(vector)\n",
    "    else:\n",
    "        matrix *= vector\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def auto_convert(matrix, threshold):\n",
    "    \"\"\"\n",
    "    Automatically convert a scipy.sparse to a numpy.ndarray if the percent\n",
    "    nonzero is above a given threshold. Automatically convert a numpy.ndarray\n",
    "    to scipy.sparse if the percent nonzero is below a given threshold.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    matrix : numpy.ndarray or scipy.sparse\n",
    "    threshold : float (0 < threshold < 1)\n",
    "        percent nonzero above which the matrix is converted to dense\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    matrix : numpy.ndarray or scipy.sparse\n",
    "    \"\"\"\n",
    "    above_thresh = (matrix != 0).sum() / numpy.prod(matrix.shape) >= threshold\n",
    "    if sparse.issparse(matrix) and above_thresh:\n",
    "        return matrix.toarray()\n",
    "    elif not above_thresh:\n",
    "        return sparse.csc_matrix(matrix)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def copy_array(matrix, copy=True):\n",
    "    \"\"\"Returns a newly allocated array if copy is True\"\"\"\n",
    "    mat_type = type(matrix)\n",
    "    if mat_type == numpy.ndarray:\n",
    "        mat_type = numpy.array\n",
    "    matrix = mat_type(matrix, dtype=numpy.float64, copy=copy)\n",
    "    assert matrix.ndim == 2\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load degree_weight.py\n",
    "import collections\n",
    "import functools\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "import numpy\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def dwwc_step(matrix, row_damping=0, column_damping=0, copy=True):\n",
    "    \"\"\"\n",
    "    Return the degree-weighted adjacency matrix produced by the input matrix\n",
    "    with the specified row and column normalization exponents.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    matrix : numpy.ndarray or scipy.sparse\n",
    "        adjacency matrix for a given metaedge, where the source nodes are\n",
    "        rows and the target nodes are columns\n",
    "    row_damping : int or float\n",
    "        exponent to use in scaling each node's row by its in-degree\n",
    "    column_damping : int or float\n",
    "        exponent to use in scaling each node's column by its column-sum\n",
    "    copy : bool\n",
    "        `True` guarantees matrix will not be modified in place. `False`\n",
    "        modifies in-place if and only if matrix.dtype == numpy.float64.\n",
    "        Users are recommended not to rely on in-place conversion, but instead\n",
    "        use `False` when in-place modification is acceptable and efficiency\n",
    "        is desired.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    numpy.ndarray or scipy.sparse\n",
    "        Normalized matrix with dtype.float64.\n",
    "    \"\"\"\n",
    "    # returns a newly allocated array\n",
    "    matrix = copy_array(matrix, copy)\n",
    "\n",
    "    row_sums = numpy.array(matrix.sum(axis=1)).flatten()\n",
    "    column_sums = numpy.array(matrix.sum(axis=0)).flatten()\n",
    "    matrix = normalize(matrix, row_sums, 'rows', row_damping)\n",
    "    matrix = normalize(matrix, column_sums, 'columns', column_damping)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def dwwc(graph, metapath, damping=0.5, sparse_threshold=0):\n",
    "    \"\"\"\n",
    "    Compute the degree-weighted walk count (DWWC). Special case of function\n",
    "    dwpc_duplicated_metanode.\n",
    "    \"\"\"\n",
    "    return dwpc_duplicated_metanode(graph, metapath, None, damping,\n",
    "                                    sparse_threshold=sparse_threshold)\n",
    "\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"\"\"\n",
    "    Yield consecutive pairs of items from the iterable, but skip pairs where\n",
    "    the items are equal.\n",
    "    Modified from recipe in itertools docs at\n",
    "    https://docs.python.org/3/library/itertools.html\n",
    "\n",
    "    s -> (s0,s1), (s1,s2), (s2, s3), ...\n",
    "    \"\"\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    for a, b in zip(a, b):\n",
    "        if b != a:\n",
    "            yield a, b\n",
    "\n",
    "\n",
    "def get_segments(metagraph, metapath):\n",
    "    \"\"\"\n",
    "    Break metapath into sub-metapaths that have at most one duplicate\n",
    "    node type.\n",
    "    \"\"\"\n",
    "    metanodes = metapath.get_nodes()\n",
    "    metanode_to_indexes = collections.OrderedDict()\n",
    "    for i, metanode in enumerate(metanodes):\n",
    "        indexes = metanode_to_indexes.setdefault(metanode, [])\n",
    "        indexes.append(i)\n",
    "\n",
    "    # Ensure no overlapping metanode duplications\n",
    "    last_stop = -1\n",
    "    for metanode, indexes in metanode_to_indexes.items():\n",
    "        if len(indexes) == 1:\n",
    "            continue\n",
    "        if min(indexes) <= last_stop:\n",
    "            msg = ('Metapath f{metapath} contains overlapping'\n",
    "                   'segments with duplicate metanodes.')\n",
    "            raise ValueError(msg)\n",
    "        last_stop = max(indexes)\n",
    "\n",
    "    # Find indices to split at\n",
    "    split_at = [0]\n",
    "    range_to_duplicate = collections.OrderedDict()\n",
    "    for metanode, indexes in metanode_to_indexes.items():\n",
    "        if len(indexes) == 1:\n",
    "            continue\n",
    "        start = min(indexes)\n",
    "        stop = max(indexes)\n",
    "        range_to_duplicate[(start, stop)] = metanode\n",
    "        split_at.append(start)\n",
    "        split_at.append(stop)\n",
    "    split_at.append(len(metapath))\n",
    "\n",
    "    # Split at indices\n",
    "    ranges = list(pairwise(split_at))\n",
    "    segments = (metapath[start:stop] for start, stop in ranges)\n",
    "    segments = [metagraph.get_metapath(metaedges) for metaedges in segments]\n",
    "    duplicates = [range_to_duplicate.get(range_, None) for range_ in ranges]\n",
    "    return segments, duplicates\n",
    "\n",
    "\n",
    "def dwpc_duplicated_metanode(graph, metapath, duplicate=None, damping=0.5,\n",
    "                             sparse_threshold=0):\n",
    "    \"\"\"\n",
    "    Compute the degree-weighted path count (DWPC) when a single metanode is\n",
    "    duplicated (any number of times). User must specify the duplicated\n",
    "    metanode.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    graph : hetio.hetnet.Graph\n",
    "    metapath : hetio.hetnet.MetaPath\n",
    "    duplicate : hetio.hetnet.MetaNode or None\n",
    "    damping : float\n",
    "    sparse_threshold : float (0 <= sparse_threshold <= 1)\n",
    "        sets the density threshold above which a sparse matrix will be\n",
    "        converted to a dense automatically.\n",
    "    \"\"\"\n",
    "    if duplicate is not None:\n",
    "        assert metapath.source() == duplicate\n",
    "    dwpc_matrix = None\n",
    "    row_names = None\n",
    "    for metaedge in metapath:\n",
    "        rows, cols, adj_mat = metaedge_to_adjacency_matrix(\n",
    "            graph, metaedge, sparse_threshold=sparse_threshold)\n",
    "        adj_mat = dwwc_step(adj_mat, damping, damping)\n",
    "        if dwpc_matrix is None:\n",
    "            row_names = rows\n",
    "            dwpc_matrix = adj_mat\n",
    "        else:\n",
    "            dwpc_matrix = dwpc_matrix @ adj_mat\n",
    "            dwpc_matrix = auto_convert(dwpc_matrix, sparse_threshold)\n",
    "        if metaedge.target == duplicate:\n",
    "            mat_type = type(dwpc_matrix)\n",
    "            if mat_type == numpy.ndarray:\n",
    "                mat_type = numpy.array\n",
    "            diag_matrix = sparse.diags(dwpc_matrix.diagonal())\n",
    "            dwpc_matrix = mat_type(dwpc_matrix - diag_matrix,\n",
    "                                   dtype=numpy.float64, copy=False)\n",
    "\n",
    "    dwpc_matrix = auto_convert(dwpc_matrix, sparse_threshold)\n",
    "    return row_names, cols, dwpc_matrix\n",
    "\n",
    "\n",
    "def dwpc(graph, metapath, damping=0.5, sparse_threshold=0):\n",
    "    \"\"\"\n",
    "    Compute the degree-weighted path count (DWPC).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        segments, duplicates = get_segments(graph.metagraph, metapath)\n",
    "    except ValueError as e:\n",
    "        raise NotImplementedError(e)\n",
    "\n",
    "    parts = list()\n",
    "    row_names = None\n",
    "    for segment, duplicate in zip(segments, duplicates):\n",
    "        if duplicate is None:\n",
    "            rows, cols, matrix = dwwc(\n",
    "                graph, segment, damping, sparse_threshold=sparse_threshold)\n",
    "        else:\n",
    "            rows, cols, matrix = dwpc_duplicated_metanode(\n",
    "                graph, segment, duplicate, damping,\n",
    "                sparse_threshold=sparse_threshold)\n",
    "        if row_names is None:\n",
    "            row_names = rows\n",
    "        parts.append(matrix)\n",
    "\n",
    "    dwpc_matrix = functools.reduce(operator.matmul, parts)\n",
    "    return row_names, cols, dwpc_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import hetio.readwrite\n",
    "import hetio.hetnet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 892 ms, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "url = '../data/hetionet-v1.0.json'\n",
    "graph = hetio.readwrite.read_graph(url)\n",
    "metagraph = graph.metagraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1206"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/metapaths.json') as data_file:\n",
    "    metapaths = json.load(data_file)\n",
    "\n",
    "metapaths.sort(key=lambda x: x['join_complexities'][0])\n",
    "\n",
    "len(metapaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the actual metapaths from the list of metapath dictionaries\n",
    "abbrevs = [metapath['abbreviation'] for metapath in metapaths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of the metapaths that are incompatible with DWPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'454 / 1206 were incompatible'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incompatible_metapaths = []\n",
    "\n",
    "for metapath in abbrevs:\n",
    "    mess = ''\n",
    "    try:\n",
    "        segments, duplicates = get_segments(graph.metagraph, metagraph.metapath_from_abbrev(metapath))\n",
    "    except ValueError:\n",
    "        mess = 'Incompatible'\n",
    "        incompatible_metapaths.append(metapath)\n",
    "'{} / {} were incompatible'.format(len(incompatible_metapaths), len(abbrevs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CiPCiCpD', 752, 454)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compatible_metapaths = [i for i in abbrevs if i not in incompatible_metapaths]\n",
    "compatible_metapaths[0], len(compatible_metapaths), len(abbrevs)-len(compatible_metapaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure that all DWPC matrices are indexed identically\n",
    "This is necessary so that we can just use indices to sort dwpcs into vectors instead of searching by row and column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows, columns, mat = dwpc(graph, metagraph.metapath_from_abbrev('CiPCiCpD'), sparse_threshold=0.25)\n",
    "exp_rows = rows\n",
    "exp_cols = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 53s, sys: 1min 13s, total: 44min 6s\n",
      "Wall time: 44min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for metapath in compatible_metapaths:\n",
    "    rows, columns, mat = dwpc(graph, metagraph.metapath_from_abbrev(metapath), sparse_threshold=0.25)\n",
    "    if (rows != exp_rows) or (columns != exp_cols):\n",
    "        print(metapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell shows that all the dwpc matrices will have the same rows and columns, meaning that the row/col combinations will be the same. So we will be able to sort the array into a vector the same way we did combinations of compound and disease names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run through all DWPC metapaths -> table of compound/disease vs metapath_dwpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compounds, diseases, mat = dwpc(graph, metagraph.metapath_from_abbrev(compatible_metapaths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compounds</th>\n",
       "      <th>diseases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0060073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  compounds      diseases\n",
       "0   DB00014  DOID:0050156\n",
       "1   DB00014  DOID:0050425\n",
       "2   DB00014  DOID:0050741\n",
       "3   DB00014  DOID:0050742\n",
       "4   DB00014  DOID:0060073"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a DataFrame with the proper compound/disease combinations\n",
    "df = []\n",
    "for compound in compounds:\n",
    "    for disease in diseases:\n",
    "        df.append([compound, disease])\n",
    "df = pd.DataFrame(df, columns=('compounds', 'diseases'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   }
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This will take many hours, probably > 7.\n",
    "n = 0\n",
    "for metapath in compatible_metapaths:\n",
    "    compounds, diseases, mat = dwpc(graph, metagraph.metapath_from_abbrev(metapath), sparse_threshold=0)\n",
    "    labels[metapath] = mat.flatten()\n",
    "    print(n)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compounds</th>\n",
       "      <th>diseases</th>\n",
       "      <th>CiPCiCpD</th>\n",
       "      <th>CiPCiCtD</th>\n",
       "      <th>CbGbCpD</th>\n",
       "      <th>CbGuCpD</th>\n",
       "      <th>CuGbCpD</th>\n",
       "      <th>CbGdCpD</th>\n",
       "      <th>CdGbCpD</th>\n",
       "      <th>CpDrD</th>\n",
       "      <th>...</th>\n",
       "      <th>CpDrDaGuD</th>\n",
       "      <th>CpDrDuGaD</th>\n",
       "      <th>CpDuGaDrD</th>\n",
       "      <th>CrCdGaD</th>\n",
       "      <th>CrCpDaGdD</th>\n",
       "      <th>CrCpDdGaD</th>\n",
       "      <th>CdGiGdD</th>\n",
       "      <th>CrCpDaGuD</th>\n",
       "      <th>CrCpDuGaD</th>\n",
       "      <th>CdGiGuD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0050742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00014</td>\n",
       "      <td>DOID:0060073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  compounds      diseases  CiPCiCpD  CiPCiCtD  CbGbCpD  CbGuCpD  CuGbCpD  \\\n",
       "0   DB00014  DOID:0050156       0.0       0.0      0.0      0.0      0.0   \n",
       "1   DB00014  DOID:0050425       0.0       0.0      0.0      0.0      0.0   \n",
       "2   DB00014  DOID:0050741       0.0       0.0      0.0      0.0      0.0   \n",
       "3   DB00014  DOID:0050742       0.0       0.0      0.0      0.0      0.0   \n",
       "4   DB00014  DOID:0060073       0.0       0.0      0.0      0.0      0.0   \n",
       "\n",
       "   CbGdCpD  CdGbCpD  CpDrD   ...     CpDrDaGuD  CpDrDuGaD  CpDuGaDrD  CrCdGaD  \\\n",
       "0      0.0      0.0    0.0   ...           0.0        0.0        0.0      0.0   \n",
       "1      0.0      0.0    0.0   ...           0.0        0.0        0.0      0.0   \n",
       "2      0.0      0.0    0.0   ...           0.0        0.0        0.0      0.0   \n",
       "3      0.0      0.0    0.0   ...           0.0        0.0        0.0      0.0   \n",
       "4      0.0      0.0    0.0   ...           0.0        0.0        0.0      0.0   \n",
       "\n",
       "   CrCpDaGdD  CrCpDdGaD  CdGiGdD  CrCpDaGuD  CrCpDuGaD  CdGiGuD  \n",
       "0        0.0        0.0      0.0        0.0        0.0      0.0  \n",
       "1        0.0        0.0      0.0        0.0        0.0      0.0  \n",
       "2        0.0        0.0      0.0        0.0        0.0      0.0  \n",
       "3        0.0        0.0      0.0        0.0        0.0      0.0  \n",
       "4        0.0        0.0      0.0        0.0        0.0      0.0  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels.to_csv('../data/metapath_dwpc.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hetmech]",
   "language": "python",
   "name": "conda-env-hetmech-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
